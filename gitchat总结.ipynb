{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gitchat总结.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "5MIkRcKtL3iu",
        "mC6_I58ViDr9",
        "SvuNdRd2lXja",
        "f5OSe0Cn1i51",
        "srZ8-pfN2Enf",
        "VRvormSY2Etc",
        "im4uLLFl4D1p",
        "O-lqdb_z-h-x",
        "d0P3zKno-iGr",
        "Xc6mwEctC4dV",
        "B0LNpqTNC4rH",
        "lthZfVF4C4x4",
        "jfUUHqWIN5P4"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccloveak/Study_Notes/blob/master/gitchat%E6%80%BB%E7%BB%93.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MIkRcKtL3iu",
        "colab_type": "text"
      },
      "source": [
        "# 机器学习该如何入门？\n",
        ">https://gitbook.cn/gitchat/activity/59566e2374ea2f222cd663f0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNYOUWozMF_K",
        "colab_type": "text"
      },
      "source": [
        "###机器学习特点：\n",
        "\n",
        "1. 机器学习以数据为研究对象，是数据驱动的科学；\n",
        "\n",
        "2. 机器学习的目的是对数据进行预测与分析；\n",
        "\n",
        "3. 机器学习以模型方法为中心，利用统计学习的方法构建模型并且利用模型对未知数据进行预测和分析；\n",
        "\n",
        "4. 统计学习是概率论、统计学、信息论、计算理论、最优化理论以及计算机科学等多领域的交叉学科，并且逐渐形成自己独自的理论体系和方法论。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zijPle8VNERq",
        "colab_type": "text"
      },
      "source": [
        "### 机器学习对象\n",
        "机器学习研究的对象是多维向量空间的数据。它从各种不同类型的数据（数字，文本，图像，音频，视频）出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到数据的分析与预测中去。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQPFu6zPNEZf",
        "colab_type": "text"
      },
      "source": [
        "### 机器学习分类"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM5RxH5LNEgj",
        "colab_type": "text"
      },
      "source": [
        "* 监督学习  监督学习是指进行训练的数据包含两部分信息：特征向量 + 类别标签。也就是说，他们在训练的时候每一个数据向量所属的类别是事先知道的。在设计学习算法的时候，学习调整参数的过程会根据类标进行调整，类似于学习的过程中被监督了一样，而不是漫无目标地去学习，故此得名。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX-W5frMNEk6",
        "colab_type": "text"
      },
      "source": [
        "* 无监督学习 相对于有监督而言，无监督方法的训练数据没有类标，只有特征向量。甚至很多时候我们都不知道总共的类别有多少个。因此，无监督学习就不叫做分类，而往往叫做聚类。就是采用一定的算法，把特征性质相近的样本聚在一起成为一类。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apX2JPabNEoY",
        "colab_type": "text"
      },
      "source": [
        "* 半监督学习 半监督学习是一种结合有监督学习和无监督学习的一种学习方式。它是近年来研究的热点，原因是在真正的模型建立的过程中，往往有类标的数据很少，而绝大多数的数据样本是没有确定类标的。这时候，我们无法直接应用有监督的学习方法进行模型的训练，因为有监督学习算法在有类标数据很少的情况下学习的效果往往很差。但是，我们也不能直接利用无监督学习的方式进行学习，因为这样，我们就没有充分的利用那些已给出的类标的有用信息。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CXEoXhzNEr6",
        "colab_type": "text"
      },
      "source": [
        "* 强化学习 所谓强化学习就是智能系统从环境到行为映射的学习，以使奖励信号(强化信号)函数值最大，强化学习不同于连接主义学习中的监督学习，主要表现在教师信号上，强化学习中由环境提供的强化信号是对产生动作的好坏作一种评价(通常为标量信号)，而不是告诉强化学习系统RLS(reinforcement learning system)如何去产生正确的动作。由于外部环境提供的信息很少，RLS必须靠自身的经历进行学习。通过这种方式，RLS在行动-评价的环境中获得知识，改进行动方案以适应环境。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvQV96riNEvw",
        "colab_type": "text"
      },
      "source": [
        "### 机器学习的要素"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syi30_24NE7N",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   模型 其实就是机器学习训练的过程中所要学习的条件概率分布或者决策函数。\n",
        "*   策略 就是使用一种什么样的评价度量模型训练过程中的学习好坏的方法，同时根据这个方法去实施的调整模型的参数，以期望训练的模型将来对未知的数据具有最好的预测准确度。\n",
        "*   算法 算法是指模型的具体计算方法。它基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后考虑用什么样的计算方法去求解这个最优模型。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6l26OC2NE-l",
        "colab_type": "text"
      },
      "source": [
        "### 数学基础"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVUSa8V_P4Hf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   微积分\n",
        "\n",
        "*   线性代数 乘法 内积运算\n",
        "\n",
        "*   概率与统计 朴素贝叶斯算法\n",
        "\n",
        "\n",
        "*   经典算法学习 \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L2U-AktQtlE",
        "colab_type": "text"
      },
      "source": [
        "#### 经典算法学习"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3afZY2nOQxTy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   分类算法： 逻辑回归（LR），朴素贝叶斯（Naive Bayes），支持向量机（SVM），随机森林（Random Forest），AdaBoost，GDBT，KNN，决策树……\n",
        "\n",
        "*   回归算法： 线性回归（Linear Regression），多项式回归（Polynomial Regression），逐步回归（Stepwise Regression），岭回归（Ridge Regression），套索回归（Lasso Regression）\n",
        "\n",
        "*   聚类算法： K均值（K-Means），谱聚类、DBSCAN聚类、模糊聚类、GMM聚类、层次聚\n",
        "\n",
        "*   降维算法： PCA（主成分分析）、SVD（奇异值分解）\n",
        "\n",
        "*   推荐算法： 协同过滤算法\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgdx6oIuRbjq",
        "colab_type": "text"
      },
      "source": [
        "### python库"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQlqHqi8RdYk",
        "colab_type": "text"
      },
      "source": [
        "*  scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nY0E3FWXKG6",
        "colab_type": "text"
      },
      "source": [
        "# 手把手教你做实时活体检测系统\n",
        "> https://gitbook.cn/books/5d1d4ccb72a3294c96090753/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yG2Smp2XQpP",
        "colab_type": "text"
      },
      "source": [
        "*  先看怎么使用colab 在colab上进行模型调整 争取9月前看完这篇文章"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zskH77Ga2TR",
        "colab_type": "text"
      },
      "source": [
        "# 机械学习极简入门\n",
        "> https://gitbook.cn/gitchat/column/5ad70dea9a722231b25ddbf8?columnId=5ad70dea9a722231b25ddbf8&refresh=true&newBuyer=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA6SyFxxa-wq",
        "colab_type": "text"
      },
      "source": [
        "## 课程大纲\n",
        "\n",
        "1.   绪论\n",
        "\n",
        "2.   基本原理\n",
        "\n",
        "3.   有监督学习 I\n",
        "\n",
        "4.   有监督学习 II\n",
        "\n",
        "5.   无监督学习\n",
        "\n",
        "6.   从机器学习到深度学习\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6H_HckFfZOu",
        "colab_type": "text"
      },
      "source": [
        "## 机器学习常用微积分知识速查手册\n",
        "> http://gitbook.cn/books/59ee907516fc0231837614e3/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDM-pxSKfc-t",
        "colab_type": "text"
      },
      "source": [
        "## 机器学习常用线性代数知识速查手册\n",
        "> http://gitbook.cn/books/59ed598e991df70ecd5a0049/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZOOQGVWfj9d",
        "colab_type": "text"
      },
      "source": [
        "## 公共 AI 支持库\n",
        "\n",
        "\n",
        "*   NumPy\n",
        "*   sklearn（scikit-learn）\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC6_I58ViDr9",
        "colab_type": "text"
      },
      "source": [
        "## python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEny0SHKg8cv",
        "colab_type": "text"
      },
      "source": [
        "### python三种不同的运行方法：\n",
        "\n",
        "1.   在命令行直接运行\n",
        "\n",
        "\n",
        "2.   编写一个 Python 文件，将 print hello world 封装为一个函数，通过 main 函数调用它来运行；\n",
        "\n",
        "\n",
        "3.   编写一个 class，将 print hello world 封装为一个 method，通过 main 函数创建 class 实例来运行 method。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP-mOPFChbqz",
        "colab_type": "text"
      },
      "source": [
        "### 编写程序练习文件读写，文件和目录操作\n",
        "*  学会将 tsv、csv 之类的文件读入 array、list、dict 等结构，以及将这些变量打印到文本文件中的方法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvuNdRd2lXja",
        "colab_type": "text"
      },
      "source": [
        "## 机器学习三要素之数据、模型、算法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baaBDEt9ljnQ",
        "colab_type": "text"
      },
      "source": [
        "### 数据\n",
        "\n",
        "*   构建一个向量空间模型（Vector Space Model，VSM）。VSM 负责将格式（文字、图片、音频、视频）转化为一个个向量\n",
        "*   无标注数据\n",
        "*   有标注数据\n",
        "*   特征工程  确定用哪些特征来表示数据； 确定用什么方式表达这些特征\n",
        "*   VSM 转换\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5tcv8ZNmdk-",
        "colab_type": "text"
      },
      "source": [
        "### 模型\n",
        "\n",
        "*   模型是机器学习的结果，这个学习过程，称为训练（Train）\n",
        "\n",
        "*   一个已经训练好的模型，可以被理解成一个函数： y=f(x)。\n",
        "\n",
        "*   模型是基于数据，经由训练得到的。\n",
        "\n",
        "*   训练就是：根据已经被指定的 f(x) 的具体形式——模型类型，结合训练数据，计算出其中各个参数的具体取值的过程。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOdQd5Bjmj_5",
        "colab_type": "text"
      },
      "source": [
        "### 算法\n",
        "\n",
        "*   有监督学习\n",
        "*   无监督学习\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqWLjk_crUTX",
        "colab_type": "text"
      },
      "source": [
        "####  监督学习"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ43ff2CrWzZ",
        "colab_type": "text"
      },
      "source": [
        "*   有监督学习的目标就是：让训练数据的所有 x 经过 f(x) 计算后，获得的 y’ 与它们原本对应的 y 的差别尽量小。\n",
        "\n",
        "*   用一个函数来描述 y’ 与 y 之间的差别，这个函数叫做损失函数（Loss Function）L（y, y’）= L(y, f(x))。\n",
        "\n",
        "*   Loss 函数针对一个训练数据，对于所有的训练数据，我们用代价函数（Cost Function）来描述整体的损失\n",
        "\n",
        "*   代价函数一般写作：J（theta）——注意，代价函数的自变量不再是 y 和 f(x)，而是变成了 theta，theta 表示 f(x) 中所有待定的参数（theta 也可以是一个向量，每个维度表示一个具体的参数）\n",
        "\n",
        "*   J（theta）的取值代表了整个模型付出的代价，这个代价自然是越小越好。\n",
        "\n",
        "*   具体的优化算法： 梯度下降法（Gradient Descent）、共轭梯度法（Conjugate Gradient）、牛顿法和拟牛顿法、模拟退火法（Simulated Annealing）\n",
        "\n",
        "*   能够决定有监督模型质量的，不是高深的算法和精密的模型，而是高质量的标注数据\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5OSe0Cn1i51",
        "colab_type": "text"
      },
      "source": [
        "## 获取模型的过程"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8yvNKkt1jEv",
        "colab_type": "text"
      },
      "source": [
        "### Step-1：数据准备"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mviacyec1jHw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   数据预处理：收集数据、清洗数据、标注数据\n",
        "\n",
        "\n",
        "2.   构建数据的向量空间模型（将文本、图片、音频、视频等格式的数据转换为向量）\n",
        "\n",
        "\n",
        "3.   将构建好向量空间模型的数据分为训练集、验证集和测试集\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDiEcEVL1jKq",
        "colab_type": "text"
      },
      "source": [
        "### Step-2：训练"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWWv4LZ91jNU",
        "colab_type": "text"
      },
      "source": [
        "*   训练集输入给训练程序，进行运算。训练程序的核心是算法，所有输入的向量化数据都会按该训练程序所依据的算法进行运算。训练程序输出的结果，就是模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9urVdhnK2EXG",
        "colab_type": "text"
      },
      "source": [
        "### Step-3：测试"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3PJiW-n2EZ4",
        "colab_type": "text"
      },
      "source": [
        "将测试集数据输入给训练获得的模型，得到预测结果；再将预测结果与这些数据原本预期的结果进行比较"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smjt0pg42EdS",
        "colab_type": "text"
      },
      "source": [
        "### 按一定规则计算模型质量的衡量指标\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xpOBbtO2Ekj",
        "colab_type": "text"
      },
      "source": [
        "比如 Precision、Recall、F1Score 等，根据指标的数值来衡量当前模型的质量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srZ8-pfN2Enf",
        "colab_type": "text"
      },
      "source": [
        "## 训练集、验证集和测试集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frI0hxvu2EqQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   训练集（Train Set）：用来做训练的数据的集合。\n",
        "\n",
        "*   验证集（Validation Set）：在训练的过程中，每个训练轮次结束后用来验证当前模型性能，为进一步优化模型提供参考的数据的集合。\n",
        "\n",
        "*   测试集（Test Set）：用来测试的数据的集合，用于检验最终得出的模型的性能。\n",
        "\n",
        "*   每个集合都应当是独立的，和另外两个没有重叠。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRvormSY2Etc",
        "colab_type": "text"
      },
      "source": [
        "## 训练的过程"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6glEwHn3XUa",
        "colab_type": "text"
      },
      "source": [
        "### 2.1编写训练程序"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqQ9afD_3XZE",
        "colab_type": "text"
      },
      "source": [
        "*   选择模型类型\n",
        "\n",
        "*   选择优化算法\n",
        "\n",
        "*   根据模型类型和算法编写程序\n",
        "\n",
        "\n",
        "*   列表项\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4_Xif_33XdN",
        "colab_type": "text"
      },
      "source": [
        "### 2.2训练 -> 获得临时模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3NfQZ-_3Xo7",
        "colab_type": "text"
      },
      "source": [
        "### 2.3在训练集上运行临时模型，获得训练集预测结果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-R2aKlZ3Xru",
        "colab_type": "text"
      },
      "source": [
        "### 2.4在验证集上运行临时模型，获得验证集预测结果。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAhZAVZt3X1J",
        "colab_type": "text"
      },
      "source": [
        "### 2.5 综合参照 Step-2.3 和 Step-2.4 的预测结果，改进模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ote2fDaX3X35",
        "colab_type": "text"
      },
      "source": [
        "### 2.6 Step-2.2 到 Step-2.5 反复迭代，直至获得让我们满意，或者已经无法继续优化的模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im4uLLFl4D1p",
        "colab_type": "text"
      },
      "source": [
        "## 改进模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FgWuDJy4D4z",
        "colab_type": "text"
      },
      "source": [
        "对照机器学习三要素，模型的优化可以从三个方面来进行：数据、算法和模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XdSZuRb4EFz",
        "colab_type": "text"
      },
      "source": [
        "### 数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-28PoL7i4EIZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   机器学习的模型质量往往和训练数据有直接的关系\n",
        "*   大量的高质量训练数据，是提高模型质量的最有效手段。\n",
        "\n",
        "*   于有监督学习而言，标注是一个痛点，通常我们可以用来训练的数据量相当有限\n",
        "*   在有限的数据上，对数据进行归一化（Normalization，又译作正规化、标准化）等操作。\n",
        "\n",
        "*   采用 Bootstrap 等采样方法处理有限的训练/测试数据，以达到更好的运算效果\n",
        "*   根据业务进行特征选取：从业务角度区分输入数据包含的特征，并理解这些特征对结果的贡献\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-D8ATB49HoM",
        "colab_type": "text"
      },
      "source": [
        "### 调参（算法）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4ZNouFn9LbF",
        "colab_type": "text"
      },
      "source": [
        "*  超参数是需要模型训练者自己来设置和调整的。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDz0s1r09Lka",
        "colab_type": "text"
      },
      "source": [
        "*   调参本身有点像一个完整的 Project，需要经历:\n",
        "\n",
        "\n",
        "\n",
        "1.   制定目标\n",
        "\n",
        "2.   制定策略\n",
        "\n",
        "3.   执行\n",
        "\n",
        "4.   验证\n",
        "\n",
        "5.   调整策略 -> 3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZhSmxz79Lpk",
        "colab_type": "text"
      },
      "source": [
        "### 模型类型选择"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soVK5y-L-h2r",
        "colab_type": "text"
      },
      "source": [
        "*   对于某个分类问题，Logistic Regression 不行，可以换 Decision Tree 或者 SVM 试试。\n",
        "*   DL 模型（CNN、DNN、RNN、LSTM 等等）训练数据不足的情况下，很可能性能更差。\n",
        "*   无论工具还是方法，选对的，别选贵的\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-lqdb_z-h-x",
        "colab_type": "text"
      },
      "source": [
        "##  分类模型评判指标： Precision、Recall 和 F1Score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaQOKgua-iBJ",
        "colab_type": "text"
      },
      "source": [
        "*   对于分类而言，最简单也是最常见的验证指标：精准率（Precision）和召回率（Recall），为了综合这两个指标并得出量化结果，又发明了 F1Score。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yZz9VHz-iD4",
        "colab_type": "text"
      },
      "source": [
        "*   精准率：Precision=TP/（TP+FP）\n",
        "*   召回率：Recall=TP/（TP+FN）\n",
        "*   F1Score = 2*(Precision * Recall)/(Precision + Recall)\n",
        "\n",
        "\n",
        "*   P、R、F1Score 在分类问题中都是对某一个类而言的。\n",
        "*   假设这个模型总共可以分10个类，那么对于每一个类都有一套独立的 P、R、F1Score 的值。衡量模型整体质量，要综合看所有10套指标，而不是只看一套\n",
        "\n",
        "*   NOTE：这几个指标也可以用于 seq2seq 识别模型的评价。\n",
        "*   seq2seq 识别实际上可以看作是一种位置相关的分类。每一种实体类型都可以被看作一个类别，因此也就同样适用 P、R、F1Score 指标。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0P3zKno-iGr",
        "colab_type": "text"
      },
      "source": [
        "## 指标对应的是模型&数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQgO8DfCC4ay",
        "colab_type": "text"
      },
      "source": [
        "*   同样一套指标，用来衡量同一个模型在不同数据集上的预测成果，最后的分数值可能不同（几乎可以肯定不同，关键是差别大小）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc6mwEctC4dV",
        "colab_type": "text"
      },
      "source": [
        "## 模型的偏差和过拟合"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc7mlXdfC4go",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   一个机器学习模型的质量问题，从对训练集样本拟合程度的角度，可以分为两类：欠拟合（Underfitting）和过拟合 （Overfitting）。\n",
        "*   bias、error 和 variance\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0LNpqTNC4rH",
        "colab_type": "text"
      },
      "source": [
        "## 最常用的优化算法——梯度下降法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNZy8vWpC4tx",
        "colab_type": "text"
      },
      "source": [
        "*   每一个机器学习模型都有一个目标函数，而学习的目标，就是最小化目标函数。\n",
        "\n",
        "*   当我们已经获得了一个函数，最小化该函数其实就是，在其自变量取值范围内，找到使得因变量最小的那个自变量取值点。\n",
        "*   几个经典机器学习模型的目标函数都是凸函数，函数的凸性保证了其有最小值。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lthZfVF4C4x4",
        "colab_type": "text"
      },
      "source": [
        "### 凸函数\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XySc9T-INYh_",
        "colab_type": "text"
      },
      "source": [
        "*   某个向量空间的凸子集（区间）上的实值函数，如果在其定义域上的任意两点 ，有 f(tx + (1-t)y) <= tf(x) + (1-t)f(y)，则称其为该区间上的凸函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9bJu_tBNobD",
        "colab_type": "text"
      },
      "source": [
        "### 梯度下降法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIxriwS8NvDo",
        "colab_type": "text"
      },
      "source": [
        "*  既然已经知道了学习的目标就是最小化目标函数的取值，而目标函数又是凸函数，那么学习的目标自然转化成了寻找某个凸函数的最小值。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJC4ohu3NvHE",
        "colab_type": "text"
      },
      "source": [
        "*   未来在应用中构建自己的目标函数，那么千万记得在直接应用任何优化算法之前，应该先确定它是凸函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g8lpv-NN5D-",
        "colab_type": "text"
      },
      "source": [
        "<script type=\"text/javascript\" src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default\"></script>\n",
        "\n",
        "1.   随机取一个自变量的值  $x_0$\n",
        "\n",
        "2.   对应该自变量算出对应点的因变量值：f($x_0$)；\n",
        "\n",
        "3.   计算 f( $x_0$) 处目标函数 f(x) 的导数；\n",
        "\n",
        "4.   从 f($x_0$ ) 开始，沿着该处目标函数导数的反方向，按一个指定的步长 $α$，向前“走一步”，走到的位置对应自变量取值为 $x_1$)；\n",
        "\n",
        "\n",
        "5.   继续重复2-4，直至退出迭代（达到指定迭代次数，或 f(x) 近似收敛到最优解）。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au33iGalN5HG",
        "colab_type": "text"
      },
      "source": [
        "### 梯度下降的超参数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue863EKxN5Kh",
        "colab_type": "text"
      },
      "source": [
        "*   步长是算法自己学习不出来的，它必须由外界指定。\n",
        "\n",
        "*   这种算法不能学习，需要人为设定的参数，就叫做超参数。\n",
        "\n",
        "*   步长参数$α$是梯度下降算法中非常重要的超参数。这个参数设置的大小如果不合适，很可能导致最终无法找到最小值点。\n",
        "*   如果目标函数不能确定只有一个极小值，而获得的模型结果又不令人满意时，就该考虑是否是在学习的过程中，优化算法进入了局部而非全局最小值。\n",
        "*   这种情况下，可以尝试几个不同的起始点。甚至尝试一下大步长，说不定反而能够跨出局部最小值点所在的凸域"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfUUHqWIN5P4",
        "colab_type": "text"
      },
      "source": [
        "## 线性回归——从模型函数到目标函数\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH-qToInN5Sf",
        "colab_type": "text"
      },
      "source": [
        "### 从数据反推公式"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nC3dnpXN5Wa",
        "colab_type": "text"
      },
      "source": [
        "### 综合利用训练数据，拟合线性回归函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfqrS5cMUhV9",
        "colab_type": "text"
      },
      "source": [
        "### 线性回归的目标函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbaDI-R-UhZW",
        "colab_type": "text"
      },
      "source": [
        "*   在将训练样本的 x 逐个带入后，得出的预测年薪 y’ = a + bx 与真实年薪 y 整体的差异最小。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huImPUfuUhc4",
        "colab_type": "text"
      },
      "source": [
        "*   具体的一个样本的 y 和 y’ 的差异用 $(y′−y)^2$来表示"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6njaVO2iUhfw",
        "colab_type": "text"
      },
      "source": [
        "*   衡量整体差距用 Cost Function  形式如下（其中 m 为样本的个数，在本例中 m 取值为6）\n",
        "$J(a,b) = \\frac{1}{2m}\\sum_{i=1}^{m}(y'^{(i)} - y^{(i)})^2 = \\frac{1}{2m}\\sum_{i=1}^{m}(a + bx^{(i)} - y^{(i)})^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k1vvVk4UhjD",
        "colab_type": "text"
      },
      "source": [
        "*   能够让因变量 J(a, b) 取值最小的自变量 a 和 b，就是最好的 a 和 b。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbeKZdQPUhmG",
        "colab_type": "text"
      },
      "source": [
        "### 线性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0Wt7VVneCRh",
        "colab_type": "text"
      },
      "source": [
        "*   线性回归模型是：利用线性函数对一个或多个自变量 （x 或 ($x_1, x_2, ... x_k$)和因变量（y）之间的关系进行拟合的模型。\n",
        "*  线性回归模型构建成功后，这个模型表现为线性函数的形式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IohDbExeCWT",
        "colab_type": "text"
      },
      "source": [
        "*   线性函数的定义是：一阶（或更低阶）多项式，或零多项式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4-ubYJZeCZG",
        "colab_type": "text"
      },
      "source": [
        "*   如果有多个独立自变量，$y = f(x_1, x_2, ..., x_k)$ 的函数形式则是：$f(x_1, x_2, ..., x_k)=a+b_1x_1+b_2x_2+...+b_kx_k$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oh2h_I3e38g",
        "colab_type": "text"
      },
      "source": [
        "*   特征是一维的，线性模型在二维空间构成一条直线；特征是二维的，线性模型在三维空间中构成一个平面；若特征是三维的，则最终模型在四维空间中构成一个体，以此类推。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6XvLEcue4DN",
        "colab_type": "text"
      },
      "source": [
        "### 用线性回归模型拟合非线性关系"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-Z-bfJgfg4Q",
        "colab_type": "text"
      },
      "source": [
        "*    设 $X=(x_1,x_2)$ ,其中 $x_1 = x^2; x_2 = x$，有：$f(x_1,x_2)=a+b_1x^2+b_2x=a+b_1x_1+b_2x_2$\n",
        "\n",
        "*   这就相当于拟合了一条二阶多项式对应的曲线\n",
        "\n",
        "*   再设 $B = (b_1, b_2)$ 则：$f(X) = a + BX$\n",
        "\n",
        "*   我们只需要在二维向量空间里训练$f(X) = a + BX$\n",
        "\n",
        "\n",
        "*   列表项\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okhyw3VMfg9m",
        "colab_type": "text"
      },
      "source": [
        "## 线性回归——梯度下降法求解目标函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLyMWl_gfhAe",
        "colab_type": "text"
      },
      "source": [
        "### 斜率、导数和偏微分"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-nJ6w0efhDm",
        "colab_type": "text"
      },
      "source": [
        "*    梯度下降法，总结起来就是：从任意点开始，在该点对目标函数求导，沿着导数方向（梯度）“走”（下降）一个给定步长，如此循环迭代，直至“走”到导数为0的位置，则达到极小值。\n",
        "\n",
        "\n",
        "*   一元函数在某一点处沿 x 轴正方向的变化率称为导数。但如果是二元或更多元的函数（自变量维度 >=2），则某一点处沿某一维度坐标轴正方向的变化率称为偏导数。\n",
        "*   导数/偏导数表现的是变化率，而变化本身，用另一个概念来表示，这个概念就是微分（对应偏导数，二元及以上函数有偏微分）。\n",
        "\n",
        "\n",
        "*   (偏）导数是针对函数上的一个点而言的，是一个值。而（偏）微分则是一个函数，其中的每个点表达的是原函数上各点沿着（偏）导数方向的变化。\n",
        "*   (偏）微分就是沿着（偏）导数的方向，产生了一个无穷小的增量\n",
        "\n",
        "\n",
        "*   当求出了一个函数的（偏）微分函数后，将某个变量带入其中，得出的（偏）微分函数对应的函数值，就是原函数在该点处，对该自变量求导的导数值。\n",
        "*   只要求出了目标函数的（偏）微分函数，那么目标函数自变量值域内每一点的导数值也就都可以求了。\n",
        "\n",
        "*   最基本的求导规则，函数（整体，而非在一个点处）求导的结果，就是微分函数\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY73jGWjfhGZ",
        "colab_type": "text"
      },
      "source": [
        "#### 常用规则中最常用的几条求导规则\n",
        "\n",
        "1.   常数的导数是零：(c)' = 0；\n",
        "\n",
        "2.   x 的 n 次幂的导数是 n 倍的 x 的 n-1 次幂：$(x^n)' = nx^{n-1}$\n",
        "\n",
        "3.   对常数乘以函数求导，结果等于该常数乘以函数的导数：(cf)' = cf'；\n",
        "4.   两个函数 f 和 g 的和的导数为：(f+g)' = f' + g'；\n",
        "\n",
        "\n",
        "5.   两个函数 f 和 g 的积的导数为：(fg)' = f'g + fg'\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pDsd-2vlY3c",
        "colab_type": "text"
      },
      "source": [
        "### 梯度下降求解目标函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdzFpV03lY6W",
        "colab_type": "text"
      },
      "source": [
        "*  $ \\frac{\\partial{J(a,b)}}{\\partial{a}} = \\frac{1}{(m)}\\sum_{i=1}^{m}((a+bx^{(i)}) - y^{(i)})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWIo85pFlZKO",
        "colab_type": "text"
      },
      "source": [
        "*   $\\frac{\\partial{J(a,b)}}{\\partial{b}} = \\frac{1}{(m)}\\sum_{i=1}^{m}x^{(i)}((a+bx^{(i)}) - y^{(i)})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx8mUoMWlZPq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   Step 1：任意给定 a 和 b 的初值。  a = 0; b = 0;\n",
        "\n",
        "*   Step 2：用梯度下降法求解 a 和 b，伪代码如下：  \n",
        "$repeat \\,\\, until\\,\\,  convergence \\{$\n",
        "\n",
        "$\\\\    \\hspace{1cm} a = a - \\alpha  \\frac{\\partial{J(a,b)}}{\\partial{a}}$  \n",
        "$ \\hspace{1cm} b = b - \\alpha  \\frac{\\partial{J(a,b)}}{\\partial{b}}$ $\\}$\n",
        "\n",
        "*   当下降的高度小于某个指定的阈值（近似收敛至最优结果），则停止下降。\n",
        "\n",
        "*   将上面展开的式子带入上面的代码，就是：\n",
        "$repeat \\,\\, until\\,\\, convergence \\{$  \n",
        "$\\hspace{1cm}sumA = 0$  \n",
        "$\\hspace{1cm}sumB = 0$  \n",
        "$\\hspace{1cm}for\\,\\, i = 1\\,\\, to\\,\\, m \\{$  \n",
        "$\\\\  \\hspace{2cm}sumA = sumA +  (a+bx^{(i)} - y^{(i)})$  \n",
        "$\\hspace{2cm}sumB = sumB + x^{(i)}(a+bx^{(i)} - y^{(i)})$    $\\}$  \n",
        "$\\hspace{1cm}a = a - \\alpha \\frac{sumA}{m}$  \n",
        "$\\hspace{1cm} b = b - \\alpha \\frac{sumB}{m}$  \n",
        "$\\}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy2MMDCzoaJO",
        "colab_type": "text"
      },
      "source": [
        "### 通用线性回归模型的目标函数求解"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr3p_uCfpvx9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   n 维自变量的线性回归模型对应的目标函数：\n",
        "$J(\\theta_0,\\theta_1, ..., \\theta_n) = \\frac{1}{(2m)}\\sum_{i=1}^{m} (y'^{(i)}-y^{(i)})^{2} = \\frac{1}{(2m)}\\sum_{i=1}^{m}(\\theta_0+\\theta_1x_1^{(i)}+\\theta_2x_2^{(i)} + ... + \\theta_n x_n^{(i)} -y^{(i)})^{2}$\n",
        "\n",
        "*   再设：$X=[x_0, x_1, x_2, ..., x_n] ，\\Theta = [\\theta_0, \\theta_1, \\theta_2, ..., \\theta_n]$\n",
        "*   $f(X) = \\Theta^{T}  X$  \n",
        "\n",
        "\n",
        "*   $h(X) = \\Theta^{T} X$\n",
        "\n",
        "\n",
        "*   相应的目标函数就是：\n",
        "$J(\\Theta) = \\frac{1}{(2m)}\\sum_{i=1}^{m}(h_\\theta(X^{(i)})-y^{(i)})^{2}$\n",
        "*   同样应用梯度下降，实现的过程是：\n",
        "$repeat\\,\\, until\\,\\, convergence \\{$  \n",
        "$\\\\    \\hspace{1cm} \\Theta \\:= \\Theta - \\alpha  \\frac{\\partial{J(\\Theta)}}{\\partial{\\Theta}}$  \n",
        "$\\}$  \n",
        "*   细化为针对 $theta_j $的形式就是：\n",
        "$repeat\\,\\, until\\,\\, convergence \\{$  \n",
        "$\\hspace{1cm}  for\\,\\, j = 1\\,\\, to\\,\\, n \\{$  \n",
        "$\\hspace{2cm} sum_j = 0$  \n",
        "$\\hspace{2cm}for\\,\\, i = 1\\,\\, to\\,\\, m\\{$  \n",
        "$\\hspace{3cm}sum_j = sum_j +  (\\theta_0 +\\theta_1x_1^{(i)}+\\theta_2x_2^{(i)}  + ... + \\theta_nx_n^{(i)} -y^{(i)})x_j^{(i)}$  \n",
        "$\\hspace{2cm}\\}$  \n",
        "$\\hspace{2cm} \\theta_j \\:= \\theta_j - \\alpha  \\frac{sum_j}{m}$  \n",
        "$\\hspace{1cm}\\}$  \n",
        "$\\}$  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFFhpsZqpv84",
        "colab_type": "text"
      },
      "source": [
        "### 线性回归的超参数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlcaIE6Ls5F2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   对于线性回归而言，只要用到梯度下降，就会有步长参数 alpha 这个超参数。\n",
        "\n",
        "*   如果训练结果偏差较大，可以尝试调小步长；如果模型质量不错但是训练效率太低，可以适当放大步长；也可以尝试使用动态步长，开始步长较大，随着梯度的缩小，步长同样缩小\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thHqUhr9s5OW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   如果训练程序是通过人工指定迭代次数来确定退出条件，则迭代次数也是一个超参数。\n",
        "\n",
        "*   如果训练程序以模型结果与真实结果的整体差值小于某一个阈值为退出条件，则这个阈值就是超参数。\n",
        "*   在模型类型和训练数据确定的情况下，超参数的设置就成了影响模型最终质量的关键。\n",
        "\n",
        "\n",
        "*   在实际应用中，能够在调参方面有章法，而不是乱试一气，就有赖于大家对于模型原理和数据的掌握了。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34JSKE_EtSwI",
        "colab_type": "text"
      },
      "source": [
        "### 编写线性回归训练/预测程序\n",
        "*   很多现成的方法库，可以直接调用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni63-7SCthlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3a1b5725-a7cb-41cf-8257-08cd3be33adb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "experiences = np.array([0,1,2,3,4,5,6,7,8,9,10])\n",
        "salaries = np.array([103100, 104900, 106800, 108700, 110400, 112300, 114200, 116100, 117800, 119700, 121600])\n",
        "\n",
        "    # 将特征数据集分为训练集和测试集，除了最后 4 个作为测试用例，其他都用于训练\n",
        "X_train = experiences[:7]\n",
        "X_train = X_train.reshape(-1,1)\n",
        "X_test = experiences[7:]\n",
        "X_test = X_test.reshape(-1,1)\n",
        "\n",
        "    # 把目标数据（特征对应的真实值）也分为训练集和测试集\n",
        "y_train = salaries[:7]\n",
        "y_test = salaries[7:]\n",
        "\n",
        "    # 创建线性回归模型\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "    # 用训练集训练模型——看就这么简单，一行搞定训练过程\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "    # 用训练得出的模型进行预测\n",
        "diabetes_y_pred = regr.predict(X_test)\n",
        "\n",
        "    # 将测试结果以图标的方式显示出来\n",
        "plt.scatter(X_test, y_test,  color='black')\n",
        "plt.plot(X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEKCQAaAkCCQASAkCGQACIn/AwhFyYg7EC1TAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}